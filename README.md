# MyTransformer
ğŸ¥°ğŸ¥°This is a Transformer architecture that uses the PyTorch framework to replicate the paper "Attention is All You Need", hoping to provide some help for beginners.

ğŸ¥°ğŸ¥°è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨PyTorchæ¡†æ¶å¤åˆ¶è®ºæ–‡ã€ŠAttention is All You Needã€‹çš„Transformeræ¶æ„ï¼Œå¸Œæœ›èƒ½ä¸ºåˆå­¦è€…æä¾›ä¸€äº›å¸®åŠ©ã€‚

ğŸ‘The various parts of the model construction have been annotated in Chinese, so you can delve into the model and explore how the transformer model works.

ğŸ‘æ¨¡å‹æ­å»ºçš„å„ä¸ªéƒ¨åˆ†å·²ç»ä½¿ç”¨ä¸­æ–‡æ³¨é‡Šæ¸…æ¥šï¼Œä½¿ç”¨å¤§å®¶å¯ä»¥æ·±å…¥æ¨¡å‹å†…éƒ¨ä»¥æ¢ç©¶transformeræ¨¡å‹æ˜¯å¦‚ä½•è¿è½¬çš„ã€‚

I copied a diagram of the transformer model architecture as follows:

æˆ‘ä¸´æ‘¹äº†ä¸€å¼ transformeræ¨¡å‹çš„æ¶æ„å›¾ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼šğŸ‘‡

![transformer architecture](/transformer.png)

## ğŸ¤–Development environment:
  torch.version  1.11.0
  cuda           11.3

Since I'm not using a visual component or a package like torchvision, torchaudio, but based on pytorch itself, the ambient pytorch version should have little impact. But a reminder to all beginners: remember to use the GPU.

å› ä¸ºæˆ‘æ²¡æœ‰ä½¿ç”¨è¯¸å¦‚å¯è§†åŒ–ç»„ä»¶æˆ–åƒtorchvision, torchaudioè¿™æ ·çš„åŒ…ï¼Œè€Œæ˜¯åŸºäºpytorchæœ¬èº«ï¼Œæ‰€ä»¥ç¯å¢ƒpytorchç‰ˆæœ¬åº”è¯¥å½±å“ä¸å¤§ã€‚ä¸è¿‡æé†’å„ä½æ–°æ‰‹ï¼šè®°å¾—ä½¿ç”¨GPUã€‚

Tips: Both the dataset (wmt14) and tokenizer used in this project can be downloaded from the Internet (e.g., from Hugging Face, etc.).

æç¤ºï¼šæœ¬é¡¹ç›®ä¸­ä½¿ç”¨çš„æ•°æ®é›†ï¼ˆwmt14ï¼‰å’Œtokenizeréƒ½å¯ä»¥ä»ç½‘ä¸Šï¼ˆæ¯”å¦‚ä»Hugging Faceç­‰ï¼‰ä¸‹è½½åˆ°ã€‚

Wish you all the best!ğŸ’“ğŸ’“

ç¥æ‚¨é¡ºåˆ©ï¼ğŸ’“ğŸ’“
