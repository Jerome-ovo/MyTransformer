{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feae8340-9699-41e9-9703-9bc9d48f0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6463e83-e31e-4947-bc38-26b03a5c5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关闭警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940fec93-16b4-479a-bf44-ef32cb287f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model          # d_model：输入和输出的特征维度，也就是模型的维度。\n",
    "        self.num_heads = num_heads      # num_heads：注意力头的数量，它用于并行计算多个注意力表示。\n",
    "        self.d_k = d_model // num_heads # 每个注意力头的维度\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)  # 查询 权重矩阵\n",
    "        self.W_k = nn.Linear(d_model, d_model)  # 键 权重矩阵\n",
    "        self.W_v = nn.Linear(d_model, d_model)  # 值 权重矩阵\n",
    "        self.W_o = nn.Linear(d_model, d_model)  # 输出 权重矩阵\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)      # dropout：dropout 的比率，用于防止过拟合。\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k) # K.transpose(-2, -1)对矩阵K执行转置操作，交换K的倒数第二个维度和最后一个维度。\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9) # 将某些位置的得分（通常是填充位置）设置为非常小的值 -1e9。这是为了在计算注意力分布时，将被掩码的元素的注意力权重压缩到几乎为零，避免影响后续计算。\n",
    "        attn = F.softmax(scores, dim=-1) # 归一化，得到注意力权重 attn，确保每一行的注意力权重和为1\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.matmul(attn, V) # 加权求和\n",
    "        return output, attn\n",
    "\n",
    "    # 实现了 多头注意力机制 中的一部分，即 分割头（split heads） 的操作\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, _ = x.size()  # x 是输入张量：查询（Q）、键（K）或值（V），形状为 (batch_size, seq_len, d_model) 批次的大小、输入序列的长度、输入的特征维度\n",
    "        return x.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2) # .view()调整形状并分割为多个头\n",
    "        # transpose(1, 2)交换第1和第2维度     (batch_size, seq_len, num_heads, d_k) -> (batch_size, num_heads, seq_len, d_k)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # 对查询、键和值分别应用对应的权重矩阵，并通过 split_heads 方法进行分割。此时得到的形状为 (batch_size, num_heads, seq_len, d_k)。\n",
    "        # 输入 Q、K 和 V 后通过这些线性层进行更新（为每个输入学习一个新的表示！！），这些变换层会在训练过程中通过梯度更新学习到更合适的表示。\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output, attn_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "\n",
    "        # .transpose(1, 2)：在多头注意力计算中，为将多个头的输出拼接成一个大的向量（即 d_model），我们需要确保这些头的信息是按每个位置来排列的，而不是按头排列。\n",
    "        # (batch_size, num_heads, seq_len, d_k) -> (batch_size, seq_len, num_heads, d_k)：通过交换，可以让每个位置（seq_len）具有 num_heads 个头的输出信息。\n",
    "        # .contiguous(): 在 PyTorch 中，当你对张量进行切片或转置后，该张量可能在内存中不再是连续存储的。调用 .contiguous() 会返回一个在内存中连续存储的新张量。这是为了确保后续调用 .view() 方法不会出错。\n",
    "        # .view()：attn_output.size(0) 是批次大小 (batch_size)；-1 表示自动推断；这使得每个位置都有一个长度为 d_model 的特征向量（前面操作方便view这一步！！！）\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(attn_output.size(0), -1, self.d_model)\n",
    "\n",
    "        # .W_o(attn_output)：attn_output是(batch_size, seq_len, num_heads * d_k)，需将其转换回原始的模型维度 d_model（=num_heads * d_k）\n",
    "        # 更重要的是：线性变换层 self.W_o 将这些来自不同头的信息统一到一个共同的空间，并对其进行学习，学到如何加权和整合不同头的信息。\n",
    "        output = self.W_o(attn_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814fcbaf-090f-4d4a-a31b-e35bd11cf190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于 Transformer 中没有循环结构（如 RNN 或 LSTM），它无法捕捉序列中单词的顺序信息，因此需要通过位置编码来显式地将序列中的位置信息加入到输入的嵌入（embedding）中\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):  # d_model 是模型的维度; max_len 是位置编码的最大长度（即最大支持的序列长度）\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)      # 用于存储所有位置的编码信息\n",
    "        # position：是形状为 (max_len, 1) 的张量，表示每个位置的索引\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)    # unsqueeze(1) 将其形状变为 (max_len, 1)\n",
    "\n",
    "        # pos：位置索引（表示序列中某个位置）。\n",
    "        # i：维度索引，( 2i ) 和 ( 2i+1 ) 分别表示偶数和奇数维度————基于偶数和奇数分开，\n",
    "        # d_{model}：模型的维度（每个词向量的维度）。\n",
    "        # 10000^{2i / d_{model}}：一个在不同维度上变化的缩放因子，控制不同维度的位置编码的 “ 频率 ” ，或者说频率因子\n",
    "        # Q：为什么不用2i和2i+1：在计算频率时，所有偶数维度和奇数维度共享相同的频率因子，但它们使用不同的数学函数（正弦和余弦）来编码相同的频率。\n",
    "        # 正弦和余弦函数的频率因子是相同的，因为它们共享相同的 周期。它们的区别仅仅在于 相位，即它们开始振荡的位置不同。\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # 为每个位置生成不同频率的正弦和余弦波\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # 0::2 表示从第 0 列开始，每隔一个位置取一个元素\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # 1::2 表示从第 1 列开始，每隔一个位置取一个元素\n",
    "\n",
    "        # .unsqueeze(0)将 pe 的形状从 (max_len, d_model) 转换为 (1, max_len, d_model)。此时，pe 的第一个维度表示“批量大小”，此处只考虑一个样本，故为1。\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # 将 pe 作为一个缓冲区（buffer）注册到模型中。缓冲区（这些张量不参与梯度计算和优化更新），此处pe存储了位置编码，会随模型一起保存和加载\n",
    "        self.register_buffer('pe', pe)\n",
    "                     \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]  # 取出 pe 中与输入x序列长度匹配的前 seq_len 个位置(1, seq_len, d_model)，与 x 的形状在维度上匹配。\n",
    "        # 加法操作不会改变维度，但它使得每个输入元素的表示同时包含了内容信息（由 x 提供）和位置信息（由 pe 提供）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77668bfa-dc58-4783-852a-219386ea80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前馈神经网络\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1): # d_model:输入的特征维度 / d_ff:前馈网络隐层的大小，即经过第一层线性变换后特征的维度 / dropout:丢弃比例\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)  # 512、2048\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)  # 2048、512\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x)) # 线性变换后采用 ReLU 激活（带来非线性，使模型能够学习更复杂的函数）\n",
    "        x = self.dropout(x)         # 随机丢弃\n",
    "        x = self.linear2(x)         # 恢复到维度 d_model\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "368ce50e-af90-4eb2-ade4-b7ac7ee03588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1): # 输入的特征维度、多头自注意力机制中的头数、前馈神经网络的隐藏层维度、丢弃率\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.ffn = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)  # 分别用于自注意力输出和前馈网络输出的正则化\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout) # 在自注意力输出和前馈网络输出后，分别应用 Dropout 操作\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)    # .self_attn(x, x, x, mask)调用多头自注意力，x 被用作查询（Q）、键（K）和值（V），是自注意力机制（Self-Attention）的标准形式\n",
    "        x = self.norm1(x + self.dropout1(attn_output)) # 残差连接（Dropout + x） + LayerNorm；然后标准化以帮助梯度传播并提高训练的稳定性\n",
    "        ffn_output = self.ffn(x)                       # 调用ffn：FeedForward 类将执行两次线性变换、ReLU 激活、以及 Dropout\n",
    "        x = self.norm2(x + self.dropout2(ffn_output))  # 同上\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ce37094-7d3d-4132-98a8-874ffa2603dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # 自注意力机制层 (Self-Attention)，用于解码器内部的输入间的注意力计算\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        # 交叉注意力机制层 (Cross-Attention)，用于解码器中计算目标序列与编码器输出的注意力\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.ffn = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)    # tgt_mask 用于遮蔽目标序列中的某些位置，通常用于防止模型看到未来的词（即因果遮蔽）\n",
    "        x = self.norm1(x + self.dropout1(attn_output))\n",
    "        # 解码器使用自身的状态去查询和提取与其生成目标相对应的源信息：x 作为查询（Q），而 encoder_output 作为键（K）和值（V）！\n",
    "        # 交叉注意力 (Cross-Attention)的计算方式与自注意力(Self-Attention)类似，不同的是它的键和值来自编码器的输出，而不是解码器的输入\n",
    "        # 这允许解码器通过注意力机制聚焦于编码器中的信息，从而在生成目标序列时参考源序列的信息\n",
    "        # encoder_output 是对源序列的信息进行“检索”的基础，其提供了所有可能需要关注的信息，所以它充当键和值\n",
    "        attn_output = self.cross_attn(x, encoder_output, encoder_output, src_mask) # src_mask 用于避免编码器（源序列）中的填充部分padding影响解码器的计算\n",
    "        x = self.norm2(x + self.dropout2(attn_output))\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm3(x + self.dropout3(ffn_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d9b445-eb96-4158-acea-ff12cf976f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer架构\n",
    "class Transformer(nn.Module):\n",
    "    \n",
    "    # **src_vocab_size 和 tgt_vocab_size**：源语言和目标语言的词汇表大小。\n",
    "    # **d_model**：每个词的表示维度，也就是模型的维度，通常在 Transformer 中设置为 512。\n",
    "    # **num_heads**：每个注意力层的多头数，通常设置为 8。\n",
    "    # **num_layers**：编码器和解码器中堆叠的层数（论文中是 6 层）。\n",
    "    # **d_ff**：前馈神经网络的隐藏层维度，通常设置为 2048。\n",
    "    # **dropout**：Dropout 用于防止过拟合。\n",
    "    \n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # 将源语言中的每个词映射为一个固定大小的稠密向量\n",
    "        # src_vocab_size 是源语言的词汇表大小，d_model 是每个词的嵌入向量的维度。nn.Embedding 会根据源语言的词汇表将每个词的索引映射到 d_model 维度的嵌入向量。\n",
    "\n",
    "        # 假设源语言有 10000 个词汇（src_vocab_size = 10000），并且我们选择 d_model = 512 作为嵌入向量的维度。\n",
    "        # 那么 nn.Embedding 会创建一个形状为 [10000, 512] 的嵌入矩阵，每一行是一个大小为 512 的词向量。\n",
    "        # 当输入一个词索引（例如 100），nn.Embedding 会返回该索引对应的 512 维词向量。\n",
    "        \n",
    "        self.encoder_embed = nn.Embedding(src_vocab_size, d_model) # 源语言嵌入层（Source Embedding Layer）\n",
    "        # tgt_vocab_size 是目标语言的词汇表大小，d_model 是嵌入向量的维度。与源语言嵌入层类似，目标语言的每个词也会通过嵌入层映射为 d_model 维的向量\n",
    "        self.decoder_embed = nn.Embedding(tgt_vocab_size, d_model) # 目标语言嵌入层（Target Embedding Layer）\n",
    "        self.pos_encoding = PositionalEncoding(d_model)            # 生成和添加位置编码\n",
    "\n",
    "        # 编码器和解码器层的初始化    N=6 ！\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        # 解码器的每个输出位置都会通过该线性层转化为目标语言中每个词的预测概率分布，从而完成最终的词生成\n",
    "        # fc：full connected 全连接层！\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size) # 将解码器的输出（维度为 d_model）映射到目标语言的词汇表大小（tgt_vocab_size）\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # encode、decode 对过程进一步封装\n",
    "    def encode(self, src, src_mask):\n",
    "        src_emb = self.dropout(self.pos_encoding(self.encoder_embed(src)))\n",
    "        for layer in self.encoder_layers:            # 依次传递给每一层编码器，复用上述定义的 encoder_layers\n",
    "            src_emb = layer(src_emb, src_mask)\n",
    "        return src_emb                               # 输出编码后的源语言表示\n",
    "    \n",
    "    def decode(self, tgt, encoder_output, src_mask, tgt_mask):\n",
    "        tgt_emb = self.dropout(self.pos_encoding(self.decoder_embed(tgt)))\n",
    "        for layer in self.decoder_layers:\n",
    "            tgt_emb = layer(tgt_emb, encoder_output, src_mask, tgt_mask)\n",
    "        return tgt_emb                               # 目标语言的解码表示\n",
    "\n",
    "    # 调用封装好的函数然后进行传播\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        encoder_output = self.encode(src, src_mask)\n",
    "        decoder_output = self.decode(tgt, encoder_output, src_mask, tgt_mask)\n",
    "        return self.fc(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db95baf-5e26-4603-8cfe-a5e4f959e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成源序列和目标序列的掩蔽矩阵\n",
    "# src 是源序列的输入、src_pad_idx 是源序列中为对齐批量数据而填充的无效词索引、tgt 是目标序列的输入、tgt_pad_idx 是目标序列中填充位置的索引\n",
    "def create_mask(src, tgt, src_pad_idx, tgt_pad_idx):\n",
    "    # unsqueeze(1).unsqueeze(2)：将 src_mask 从形状 [batch_size, seq_len] 转换为 [batch_size, 1, 1, seq_len]\n",
    "    # 在计算注意力时需要将 “掩蔽矩阵” 与 “查询、键、值矩阵” 的维度匹配\n",
    "    src_mask = (src != src_pad_idx).unsqueeze(1).unsqueeze(2) # 比较得到布尔值张量，填充位置为 False，非填充位置为 True\n",
    "    tgt_mask = (tgt != tgt_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "    seq_len = tgt.size(1)  # 获取目标序列 tgt 在第一个维度（即 seq_len）上的大小，也就是目标序列的长度\n",
    "    # nopeak_mask = (1 - torch.triu(torch.ones(1, seq_len, seq_len), diagonal=1)).bool()\n",
    "    nopeak_mask = torch.tril(torch.ones(seq_len, seq_len)).bool() # 创建一个大小为 (seq_len, seq_len) 的全 1 张量，提取下三角矩阵（包括主对角线），转换为布尔类型\n",
    "    tgt_mask = tgt_mask & nopeak_mask.to(tgt.device) # 确保掩蔽矩阵与目标序列的张量在相同的设备上，目标序列中的填充位置和未来位置都将被遮蔽掉\n",
    "    return src_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6fe8a2-04c7-4d48-b677-1e7372ca9382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 论文中没有详细列出具体的初始化方法！！\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1: # 检查模型层 m 是否有 weight 属性；> 1排除如 偏置项 这样的单一维度的参数\n",
    "        nn.init.xavier_uniform_(m.weight.data)      # 使用 Xavier 均匀分布初始化 来初始化该层的权重，m.weight.data访问层的权重张量\n",
    "\n",
    "# # 初始化一个 Transformer 模型，src_vocab_size 和 tgt_vocab_size 分别是源语言和目标语言的词汇表大小\n",
    "# model = Transformer(src_vocab_size=10000, tgt_vocab_size=10000)\n",
    "# # apply 函数会递归地遍历模型中的每一层（即每一个子模块），并将 initialize_weights 函数应用于每一层，对其权重进行 Xavier 初始化\n",
    "# model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1ffc5-bedf-4879-8af1-7e6b432204d4",
   "metadata": {},
   "source": [
    "## 测试！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e60a0f54-1196-4abe-899e-7ff41719adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce1e465-ab9d-46f0-92ed-e6856722e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. 定义模型    ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42a24e37-eba5-4ca7-910e-e48a715fb879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6166fc6426e74b84b90edffa1b694663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a20e401760846bf98b56da0f0d0f497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 40836715\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n",
      "{'translation': {'en': 'Resumption of the session', 'fr': 'Reprise de la session'}}\n"
     ]
    }
   ],
   "source": [
    "# ---- 2. 加载数据集  ----\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 加载 WMT 2014 英语到法语数据集\n",
    "dataset = load_dataset(\"wmt14\", \"fr-en\")\n",
    "# 查看数据集的不同部分\n",
    "print(dataset)  # 输出包含训练、验证和测试集合的信息\n",
    "# 查看训练集中前几个样本\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37f10147-a769-49da-a642-e194b3102eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 3. 配置训练参数 ----\n",
    "src_pad_idx = tgt_pad_idx = 0\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fef81f4-142b-4cad-aab2-98b2b34f90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 替换为支持翻译任务的Tokenizer\n",
    "from transformers import MarianTokenizer\n",
    "tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df8fc4ef-70ad-497f-a99a-da4a15dd8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数据集：分词并将数据集转为 token id\n",
    "def tokenize_function(examples):\n",
    "    # 获取源语言（英语）和目标语言（法语）\n",
    "    source_texts = [example['en'] for example in examples['translation']]\n",
    "    target_texts = [example['fr'] for example in examples['translation']]\n",
    "    \n",
    "    # 对源文本（英语）进行分词\n",
    "    model_inputs = tokenizer(source_texts, truncation=True, padding=\"max_length\", max_length=64)\n",
    "    # 对目标文本（法语）进行分词，并将其作为标签\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(target_texts, truncation=True, padding=\"max_length\", max_length=64)\n",
    "    \n",
    "    # 将目标文本的 token id 添加到模型输入中作为 labels\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    # 转换为 torch.Tensor，确保数据是张量\n",
    "    model_inputs[\"input_ids\"] = torch.tensor(model_inputs[\"input_ids\"])\n",
    "    model_inputs[\"attention_mask\"] = torch.tensor(model_inputs[\"attention_mask\"])\n",
    "    model_inputs[\"labels\"] = torch.tensor(labels[\"input_ids\"])\n",
    "    return model_inputs\n",
    "\n",
    "# 选择前 100000 条记录以减少训练时间，您可以根据需求创建较小的数据集\n",
    "small_train_dataset = dataset['train'].select(range(10000))\n",
    "small_val_dataset = dataset['validation'].select(range(3000))\n",
    "small_test_dataset = dataset['test'].select(range(3000))\n",
    "\n",
    "# 应用分词函数\n",
    "tokenized_train_datasets = small_train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_datasets = small_val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_datasets = small_test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# tokenized_train_datasets = dataset['train'].map(tokenize_function, batched=True)\n",
    "# tokenized_val_datasets = dataset['validation'].map(tokenize_function, batched=True)\n",
    "# tokenized_test_datasets = dataset['test'].map(tokenize_function, batched=True)\n",
    "\n",
    "# 将数据集格式设置为 PyTorch tensors\n",
    "tokenized_train_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_val_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_test_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_dataloader = DataLoader(tokenized_train_datasets, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(tokenized_val_datasets, batch_size=32)\n",
    "test_dataloader = DataLoader(tokenized_test_datasets, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5552d215-ed25-48c2-9b64-44088793e17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  # 打印模型的设备，确保它是在 GPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be10020e-fd1d-499f-801a-9d243a323faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embed): Embedding(59514, 512)\n",
       "  (decoder_embed): Embedding(59514, 512)\n",
       "  (pos_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0): EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0): DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=59514, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据实际词汇表大小初始化模型\n",
    "model = Transformer(\n",
    "    src_vocab_size=tokenizer.vocab_size,\n",
    "    tgt_vocab_size=tokenizer.vocab_size,\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    num_layers=3\n",
    ").to(device)\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0929ecc1-646d-4725-9c16-82e018957d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "# 检查 train_dataloader 中的 batch 结构 (只需要打印一次)\n",
    "for batch in train_dataloader:\n",
    "    print(batch.keys())  # 确认有 input_ids 和 labels 字段\n",
    "    break  # 只打印第一个 batch，避免输出过多信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16eb4298-bb8a-490e-9610-7b955c333154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([  660, 10252,   529,  3498,     7,     4,   269,     0, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([  660, 14717,     5,     8,   269,     0, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513])}\n"
     ]
    }
   ],
   "source": [
    "# 打印一些样本\n",
    "print(tokenized_train_datasets[0])  # 打印第一个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2be6aae8-d996-4044-8a61-56f96a884703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 确保 DataLoader 能正常工作\n",
    "# for i, batch in enumerate(train_dataloader):\n",
    "#     print(f\"Batch {i + 1}:\")\n",
    "#     print(batch.keys())  # 打印 batch 的键\n",
    "#     print(f\"input_ids shape: {batch['input_ids'].shape}\")  # 查看 input_ids 的形状\n",
    "#     print(f\"labels shape: {batch['labels'].shape}\")  # 查看 labels 的形状\n",
    "#     print('-' * 50)\n",
    "#     if i == 2:  # 查看前 3 个批次\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d77daf17-abe9-4b45-b16f-829206c04fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: Resumption of the session\n",
      "Encoded input: {'input_ids': [660, 10252, 529, 3498, 7, 4, 269, 0, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# 检查tokenizer\n",
    "# 查看第一个样本的分词结果\n",
    "sample_text = dataset['train'][0]['translation']['en']  # 获取英文原文\n",
    "print(\"Sample text:\", sample_text)\n",
    "\n",
    "# 使用 tokenizer 进行编码\n",
    "encoded_input = tokenizer(sample_text, truncation=True, padding='max_length', max_length=64)\n",
    "print(\"Encoded input:\", encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf6f7906-21c5-4473-8acc-5bcf1063a169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "input_ids (first item): tensor([  627,     2,    48,    47,    79,  1016,  3425,     2,   192,   314,\n",
      "        35524,  1729, 15605,   835,    12,    45,   289,     7,  5606,    10,\n",
      "        23312,     3,     0, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513])\n",
      "labels (first item): tensor([  679,   157,    19, 23318,    78,   371,  2205, 11319,   283, 39103,\n",
      "           17,  5088,     8,  4805,    11,    14,     6,  4261,     3,     0,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 假设 train_dataloader 已经定义并加载数据\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    if i < 1:  # 只查看前 1 个批次\n",
    "        print(f\"Batch {i + 1}:\")\n",
    "        print(batch.keys())  # 输出字段名\n",
    "        # 查看 'input_ids' 和 'labels' 的前几个元素\n",
    "        print(f\"input_ids (first item): {batch['input_ids'][0]}\")\n",
    "        print(f\"labels (first item): {batch['labels'][0]}\")\n",
    "        print('-' * 50)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "238118dc-de0d-4c80-8427-6f179080c925",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|███████████████████████████████████████████████████████████████████| 313/313 [01:23<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 4.500332522316101\n",
      "Validation Loss: 5.117064080339797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|███████████████████████████████████████████████████████████████████| 313/313 [01:25<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 3.8859990496224106\n",
      "Validation Loss: 4.943279766021891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|███████████████████████████████████████████████████████████████████| 313/313 [01:24<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss: 3.498775059422746\n",
      "Validation Loss: 4.646818150865271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|███████████████████████████████████████████████████████████████████| 313/313 [01:21<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Loss: 3.1558052548966087\n",
      "Validation Loss: 4.264460939042111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|███████████████████████████████████████████████████████████████████| 313/313 [01:21<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Loss: 2.8642268919716245\n",
      "Validation Loss: 4.173023581504822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|███████████████████████████████████████████████████████████████████| 313/313 [01:17<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Loss: 2.6018804026107056\n",
      "Validation Loss: 3.837663044320776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|███████████████████████████████████████████████████████████████████| 313/313 [01:21<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Loss: 2.3670422010147534\n",
      "Validation Loss: 3.6685718145776303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|███████████████████████████████████████████████████████████████████| 313/313 [01:18<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Loss: 2.161351465188657\n",
      "Validation Loss: 3.563083514254144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|███████████████████████████████████████████████████████████████████| 313/313 [01:19<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Loss: 1.9773917655213573\n",
      "Validation Loss: 3.3822655601704374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Loss: 1.8073353527453\n",
      "Validation Loss: 3.4110351496554436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:21<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Loss: 1.6561817597276487\n",
      "Validation Loss: 3.307791146826237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:23<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Loss: 1.5187404102410753\n",
      "Validation Loss: 3.0481175108158842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:19<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Loss: 1.3960940209440529\n",
      "Validation Loss: 3.151737602467233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:17<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Loss: 1.2867535230831597\n",
      "Validation Loss: 3.1675241931955864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:25<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Loss: 1.1865163194104886\n",
      "Validation Loss: 3.0267962889468416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:21<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Loss: 1.0979053724688081\n",
      "Validation Loss: 2.9231295712450716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:20<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Loss: 1.0158301959403406\n",
      "Validation Loss: 2.775716226151649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:19<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Loss: 0.9433060907327329\n",
      "Validation Loss: 2.9340367317199707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:20<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Loss: 0.8741922174779752\n",
      "Validation Loss: 2.743103945508916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:21<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Loss: 0.8117679812656805\n",
      "Validation Loss: 2.8007159841821547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:24<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Loss: 0.754132688426362\n",
      "Validation Loss: 2.649806611081387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:22<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Loss: 0.7005077172011233\n",
      "Validation Loss: 2.6664147605287267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:20<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Loss: 0.6532672012385469\n",
      "Validation Loss: 2.658354388906601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:19<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Loss: 0.6047168723500955\n",
      "Validation Loss: 2.6279350227497993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:26<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Loss: 0.5642289431712117\n",
      "Validation Loss: 2.5562054755839894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:22<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Loss: 0.52332913504241\n",
      "Validation Loss: 2.5633068059353117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:20<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Loss: 0.486811615026797\n",
      "Validation Loss: 2.581449974090495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:18<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Loss: 0.45085463394372227\n",
      "Validation Loss: 2.5509242034972983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:18<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Loss: 0.4187525685031574\n",
      "Validation Loss: 2.5617484203044403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:19<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Loss: 0.3866661406172731\n",
      "Validation Loss: 2.486630966688724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:26<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 - Loss: 0.3582762489779689\n",
      "Validation Loss: 2.469617948253104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:20<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 - Loss: 0.3306336169616102\n",
      "Validation Loss: 2.4138279271886702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:18<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 - Loss: 0.3048651501203117\n",
      "Validation Loss: 2.4180684983730316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:21<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 - Loss: 0.2805004822084317\n",
      "Validation Loss: 2.40566637097521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:19<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 - Loss: 0.25584690934552934\n",
      "Validation Loss: 2.420526221077493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:27<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 - Loss: 0.23416388577546554\n",
      "Validation Loss: 2.379218544097657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:16<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 - Loss: 0.21459062992574307\n",
      "Validation Loss: 2.3188373864965235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:18<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 - Loss: 0.1950527841147904\n",
      "Validation Loss: 2.353210730755583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:21<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 - Loss: 0.1769103477366816\n",
      "Validation Loss: 2.3204509539807097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████████████████████████████████████████████████████████████| 313/313 [01:18<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 - Loss: 0.15869916254243913\n",
      "Validation Loss: 2.3452338011974985\n",
      "Early stopping activated. Stopping training at epoch 40.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: 训练模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # 用于进度条显示\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "\n",
    "# 设置早停参数\n",
    "early_stopping_patience = 3  # 连续多少个 epoch 没有改进就停止\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# 假设train_dataloader是焕发过训练集，val_loader是真正验证集\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "        src = batch['input_ids'].to(device)\n",
    "        tgt = batch['labels'].to(device)\n",
    "\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 创建 mask，在实际中可能需要注意 padding token 的索引值。\n",
    "        src_mask = (src != tokenizer.pad_token_id).unsqueeze(1).unsqueeze(2)    \n",
    "        tgt_input = tgt[:-1, :]            \n",
    "        tgt_mask = (tgt != tokenizer.pad_token_id).unsqueeze(1).unsqueeze(2)   \n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(src=src, \n",
    "                        tgt=tgt,\n",
    "                        src_mask=src_mask, \n",
    "                        tgt_mask=tgt_mask)\n",
    "        \n",
    "        outputs_flat = outputs[:, 1:, :].reshape(-1, outputs.shape[-1]) \n",
    "        target_flat = tgt[:, 1:].reshape(-1)  \n",
    "        \n",
    "        assert outputs_flat.shape[0] == target_flat.shape[0], f\"Shape mismatch: {outputs_flat.shape[0]} != {target_flat.shape[0]}\"\n",
    "        \n",
    "        loss = criterion(outputs_flat, target_flat)  \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1} - Loss: {average_loss}\")\n",
    "    \n",
    "    # 验证阶段，计算验证损失以监控性能变化\n",
    "    model.eval()  # 切换到评估模式\n",
    "    val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_dataloader:  # 验证数据加载器\n",
    "            val_src = val_batch['input_ids'].to(device)\n",
    "            val_tgt = val_batch['labels'].to(device)\n",
    "\n",
    "            src_mask_val = (val_src != tokenizer.pad_token_id).unsqueeze(1).unsqueeze(2)    \n",
    "            val_tgt_input = val_tgt[:-1, :]            \n",
    "            tgt_mask_val = (val_tgt != tokenizer.pad_token_id).unsqueeze(1).unsqueeze(2)   \n",
    "\n",
    "            val_outputs = model(src=val_src, \n",
    "                                tgt=val_tgt,\n",
    "                                src_mask=src_mask_val, \n",
    "                                tgt_mask=tgt_mask_val)\n",
    "            \n",
    "            val_outputs_flat = val_outputs[:, 1:, :].reshape(-1, val_outputs.shape[-1]) \n",
    "            val_target_flat = val_tgt[:, 1:].reshape(-1)\n",
    "\n",
    "            assert val_outputs_flat.shape[0] == val_target_flat.shape[0], f\"Shape mismatch: {val_outputs_flat.shape[0]} != {val_target_flat.shape[0]}\"\n",
    "            \n",
    "            val_loss += criterion(val_outputs_flat, val_target_flat).item()\n",
    "\n",
    "    average_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f\"Validation Loss: {average_val_loss}\")\n",
    "\n",
    "    # Early Stopping Logic\n",
    "    if average_val_loss < best_loss:\n",
    "        best_loss = average_val_loss\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # 保存最佳模型参数\n",
    "        torch.save(model.state_dict(), \"transformer_wmt14_fr_en_best.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(f\"Early stopping activated. Stopping training at epoch {epoch + 1}.\")\n",
    "        break\n",
    "\n",
    "# 保存最终训练好的模型（如果需要）\n",
    "torch.save(model.state_dict(), \"transformer_wmt14_fr_en_final.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cefcff40-0b20-47dd-a67a-71bd6c3fda4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max index in tgt: 59513\n"
     ]
    }
   ],
   "source": [
    "# 确保目标序列中的最大索引\n",
    "print(\"Max index in tgt:\", max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be82f596-c933-46a1-a31c-d7b1d624c028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max index in source input: tensor(59513, device='cuda:0')\n",
      "Max index in target input: tensor(59513, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Max index in source input:\", src.max())\n",
    "print(\"Max index in target input:\", tgt.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e50b8974-6661-41fa-8724-e65d69c3d818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding weight shape: torch.Size([59514, 512])\n",
      "Embedding weight shape: torch.Size([59514, 512])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding weight shape: {model.encoder_embed.weight.shape}\")  # 对于 source embedding\n",
    "print(f\"Embedding weight shape: {model.decoder_embed.weight.shape}\")  # 对于 target embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d29ffb4-1477-44d2-a89c-4bf7c1b69d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: 加载模型并进行预测\n",
    "\n",
    "# 加载训练好的模型\n",
    "model.load_state_dict(torch.load(\"transformer_wmt14_fr_en.pth\"))\n",
    "model.eval()  # 设置为评估模式\n",
    "\n",
    "# 定义翻译函数\n",
    "def translate(sentence, tokenizer, model, device):\n",
    "    # 对输入句子进行编码\n",
    "    src = tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n",
    "    tgt = torch.ones((1, 1), dtype=torch.long).fill_(tokenizer.pad_token_id).to(device)  # 初始输入为 padding token\n",
    "\n",
    "    # 生成 src_mask\n",
    "    src_mask = (src != tokenizer.pad_token_id).unsqueeze(1).unsqueeze(2)  # 生成 src_mask\n",
    "    # 初始化 tgt_mask (开始时的 tgt_mask 为仅对当前 token 开放)\n",
    "    tgt_mask = torch.triu(torch.ones(1, 1, 1, 1, device=device), diagonal=1)  # 上三角矩阵\n",
    "\n",
    "    # print(\"源句子:\", sentence)\n",
    "    # print(\"编码后的源:\", tokenizer.decode(src[0], skip_special_tokens=True))\n",
    "    # print(\"\\n翻译过程:\\n\" + \"=\"*30)\n",
    "\n",
    "    # 进行推理\n",
    "    with torch.no_grad():\n",
    "        for _ in range(64):  # 最多生成64个token\n",
    "            # 传递 src 和 tgt 以及对应的掩码\n",
    "            output = model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)  \n",
    "            next_token = output.argmax(dim=-1)[:, -1]  # 获取预测的下一个token\n",
    "            tgt = torch.cat([tgt, next_token.unsqueeze(0)], dim=1)  # 将预测的 token 添加到 tgt\n",
    "\n",
    "            # 打印当前预测信息\n",
    "            # print(f\"当前目标序列: {tokenizer.decode(tgt[0], skip_special_tokens=True)}\")\n",
    "            # print(f\"预测的下一个 token ID: {next_token.item()}, 对应字符: '{tokenizer.decode(next_token)}'\\n\")\n",
    "\n",
    "            # 更新 tgt_mask：为新的生成的 token 创建一个新的目标掩码\n",
    "            new_tgt_mask = torch.triu(torch.ones(1, 1, tgt.size(1), tgt.size(1), device=device), diagonal=1)\n",
    "            tgt_mask = new_tgt_mask  # 每次生成新的 tgt_mask 进行替换，不需要拼接\n",
    "            \n",
    "            if next_token.item() == tokenizer.eos_token_id:  # 如果预测结束标记，则停止\n",
    "                # print(\"生成结束，遇到结束标记。\")\n",
    "                break\n",
    "\n",
    "    # 解码预测的token id为句子\n",
    "    translation = tokenizer.decode(tgt[0], skip_special_tokens=True)\n",
    "    return translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08bb849d-41ba-4814-87ab-d4e758af243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: Resumption of the session\n",
      "Translation: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Resumption of the session\"\n",
    "translation = translate(sentence, tokenizer, model, device)\n",
    "print(f\"Original Sentence: {sentence}\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9856416-610f-413a-bcfc-bc5be9980eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: This is a test sentence.\n",
      "Translation: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "# 示例翻译\n",
    "sentence = \"This is a test sentence.\"\n",
    "translation = translate(sentence, tokenizer, model, device)\n",
    "print(f\"Original Sentence: {sentence}\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2023",
   "language": "python",
   "name": "pytorch2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
